{
    "name": "root",
    "gauges": {
        "BalanceBoard.Policy.Entropy.mean": {
            "value": 0.47509434819221497,
            "min": 0.47509434819221497,
            "max": 1.4221034049987793,
            "count": 132
        },
        "BalanceBoard.Policy.Entropy.sum": {
            "value": 14349.75,
            "min": 14179.9619140625,
            "max": 42818.84765625,
            "count": 132
        },
        "BalanceBoard.Environment.EpisodeLength.mean": {
            "value": 12.992366412213741,
            "min": 8.869407894736842,
            "max": 13.001418439716312,
            "count": 132
        },
        "BalanceBoard.Environment.EpisodeLength.sum": {
            "value": 27232.0,
            "min": 26907.0,
            "max": 27870.0,
            "count": 132
        },
        "BalanceBoard.Step.mean": {
            "value": 3959334.0,
            "min": 29993.0,
            "max": 3959334.0,
            "count": 132
        },
        "BalanceBoard.Step.sum": {
            "value": 3959334.0,
            "min": 29993.0,
            "max": 3959334.0,
            "count": 132
        },
        "BalanceBoard.Policy.ExtrinsicValueEstimate.mean": {
            "value": -43.45591354370117,
            "min": -45.07121658325195,
            "max": -6.558416366577148,
            "count": 132
        },
        "BalanceBoard.Policy.ExtrinsicValueEstimate.sum": {
            "value": -91127.046875,
            "min": -131027.8203125,
            "max": -19931.02734375,
            "count": 132
        },
        "BalanceBoard.Environment.CumulativeReward.mean": {
            "value": -43.31058662825672,
            "min": -45.3659098161683,
            "max": -43.29342168978589,
            "count": 132
        },
        "BalanceBoard.Environment.CumulativeReward.sum": {
            "value": -90822.30015945435,
            "min": -137866.99993133545,
            "max": -90077.00011062622,
            "count": 132
        },
        "BalanceBoard.Policy.ExtrinsicReward.mean": {
            "value": -43.31058662825672,
            "min": -45.3659098161683,
            "max": -43.29342168978589,
            "count": 132
        },
        "BalanceBoard.Policy.ExtrinsicReward.sum": {
            "value": -90822.30015945435,
            "min": -137866.99993133545,
            "max": -90077.00011062622,
            "count": 132
        },
        "BalanceBoard.Losses.PolicyLoss.mean": {
            "value": 0.016035510406072716,
            "min": 0.012513014913808244,
            "max": 0.02326032907391588,
            "count": 132
        },
        "BalanceBoard.Losses.PolicyLoss.sum": {
            "value": 0.03207102081214543,
            "min": 0.012554171108058653,
            "max": 0.0463327121584977,
            "count": 132
        },
        "BalanceBoard.Losses.ValueLoss.mean": {
            "value": 1.9497077147165933,
            "min": 0.10207309313118458,
            "max": 1094.4438242594401,
            "count": 132
        },
        "BalanceBoard.Losses.ValueLoss.sum": {
            "value": 3.8994154294331866,
            "min": 0.10251386066277822,
            "max": 1094.4438242594401,
            "count": 132
        },
        "BalanceBoard.Policy.LearningRate.mean": {
            "value": 6.332380889208996e-05,
            "min": 6.332380889208996e-05,
            "max": 0.00029877090040970005,
            "count": 132
        },
        "BalanceBoard.Policy.LearningRate.sum": {
            "value": 0.00012664761778417993,
            "min": 6.5169078277e-05,
            "max": 0.0005913942628685798,
            "count": 132
        },
        "BalanceBoard.Policy.Epsilon.mean": {
            "value": 0.12110791000000001,
            "min": 0.12110791000000001,
            "max": 0.19959029999999994,
            "count": 132
        },
        "BalanceBoard.Policy.Epsilon.sum": {
            "value": 0.24221582000000003,
            "min": 0.12172299999999997,
            "max": 0.39713142,
            "count": 132
        },
        "BalanceBoard.Policy.Beta.mean": {
            "value": 0.0010632847089999996,
            "min": 0.0010632847089999996,
            "max": 0.004979555969999998,
            "count": 132
        },
        "BalanceBoard.Policy.Beta.sum": {
            "value": 0.0021265694179999992,
            "min": 0.0010939777000000006,
            "max": 0.009856857858000001,
            "count": 132
        },
        "BalanceBoard.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 132
        },
        "BalanceBoard.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 132
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1717831783",
        "python_version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Programmation\\Unity\\mlagents-sandbox\\mlagents-venv\\Scripts\\mlagents-learn config\\BalanceBoard.yaml --run-id BalanceBoard",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.3.0+cu121",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1717834800"
    },
    "total": 3017.4296490999986,
    "count": 1,
    "self": 0.005257600001641549,
    "children": {
        "run_training.setup": {
            "total": 0.057476499991025776,
            "count": 1,
            "self": 0.057476499991025776
        },
        "TrainerController.start_learning": {
            "total": 3017.366915000006,
            "count": 1,
            "self": 4.232700998501969,
            "children": {
                "TrainerController._reset_env": {
                    "total": 5.935086199999205,
                    "count": 1,
                    "self": 5.935086199999205
                },
                "TrainerController.advance": {
                    "total": 3007.027234501511,
                    "count": 299904,
                    "self": 3.8794770020176657,
                    "children": {
                        "env_step": {
                            "total": 1381.235609500276,
                            "count": 299904,
                            "self": 1023.5257868009649,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 355.17123490036465,
                                    "count": 299904,
                                    "self": 6.009156197673292,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 349.16207870269136,
                                            "count": 110795,
                                            "self": 349.16207870269136
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.538587798946537,
                                    "count": 299904,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3006.8961050063954,
                                            "count": 299904,
                                            "is_parallel": true,
                                            "self": 2226.9208029107394,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0005072000058135018,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00022479999461211264,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00028240001120138913,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00028240001120138913
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 779.9747948956501,
                                                    "count": 299904,
                                                    "is_parallel": true,
                                                    "self": 30.542533904852462,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 60.38976809816086,
                                                            "count": 299904,
                                                            "is_parallel": true,
                                                            "self": 60.38976809816086
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 619.3838338977366,
                                                            "count": 299904,
                                                            "is_parallel": true,
                                                            "self": 619.3838338977366
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 69.65865899490018,
                                                            "count": 299904,
                                                            "is_parallel": true,
                                                            "self": 31.530802991546807,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 38.12785600335337,
                                                                    "count": 599808,
                                                                    "is_parallel": true,
                                                                    "self": 38.12785600335337
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1621.9121479992173,
                            "count": 299904,
                            "self": 5.080755603994476,
                            "children": {
                                "process_trajectory": {
                                    "total": 1104.3376438951964,
                                    "count": 299904,
                                    "self": 1103.6472234951652,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.6904204000311438,
                                            "count": 7,
                                            "self": 0.6904204000311438
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 512.4937485000264,
                                    "count": 194,
                                    "self": 376.64440429979004,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 135.84934420023637,
                                            "count": 5820,
                                            "self": 135.84934420023637
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.0999938240274787e-06,
                    "count": 1,
                    "self": 1.0999938240274787e-06
                },
                "TrainerController._save_models": {
                    "total": 0.17189220000000205,
                    "count": 1,
                    "self": 0.019545200004358776,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.15234699999564327,
                            "count": 1,
                            "self": 0.15234699999564327
                        }
                    }
                }
            }
        }
    }
}